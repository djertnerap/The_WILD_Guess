Dataset: fmow
Algorithm: ERM
Root dir: ./data
Split scheme: official
Dataset kwargs: {'seed': 111, 'use_ood_val': True}
Download: True
Frac: 1.0
Version: None
Unlabeled split: None
Unlabeled version: None
Use unlabeled y: False
Loader kwargs: {'num_workers': 4, 'pin_memory': True}
Unlabeled loader kwargs: {'num_workers': 8, 'pin_memory': True}
Train loader: standard
Uniform over groups: False
Distinct groups: None
N groups per batch: 8
Unlabeled n groups per batch: 8
Batch size: 32
Unlabeled batch size: 32
Eval loader: standard
Gradient accumulation steps: 1
Model: densenet121
Model kwargs: {'pretrained': True}
Noisystudent add dropout: None
Noisystudent dropout rate: None
Pretrained model path: None
Load featurizer only: False
Teacher model path: None
Transform: image_base
Additional train transform: None
Target resolution: (224, 224)
Resize scale: None
Max token length: None
Randaugment n: 2
Loss function: cross_entropy
Loss kwargs: {}
Groupby fields: ['year']
Group dro step size: None
Coral penalty weight: 0.1
Dann penalty weight: 1.0
Dann classifier lr: 0.0001
Dann featurizer lr: 1e-05
Dann discriminator lr: 0.0001
Afn penalty weight: None
Safn delta r: None
Hafn r: None
Use hafn: False
Irm lambda: 1.0
Irm penalty anneal iters: None
Self training lambda: None
Self training threshold: None
Pseudolabel t2: None
Soft pseudolabels: False
Algo log metric: accuracy
Process pseudolabels function: pseudolabel_multiclass_logits
Val metric: acc_worst_region
Val metric decreasing: False
N epochs: 60
Optimizer: Adam
Lr: 0.0001
Weight decay: 0.0
Max grad norm: None
Optimizer kwargs: {}
Scheduler: StepLR
Scheduler kwargs: {'gamma': 0.96, 'step_size': 1}
Scheduler metric split: val
Scheduler metric name: None
Process outputs function: multiclass_logits_to_pred
Evaluate all splits: True
Eval splits: []
Eval only: False
Eval epoch: None
Device: cuda
Seed: 0
Log dir: ./logs
Log every: 50
Save step: None
Save best: True
Save last: True
Save pred: True
No group logging: False
Progress bar: False
Resume: False
Use wandb: False
Wandb api key path: None
Wandb kwargs: {}
Use data parallel: False

Train data...
    year = 2002: n = 1455
    year = 2003: n = 1985
    year = 2004: n = 1545
    year = 2005: n = 2207
    year = 2006: n = 2765
    year = 2007: n = 1338
    year = 2008: n = 1975
    year = 2009: n = 6454
    year = 2010: n = 16498
    year = 2011: n = 19237
    year = 2012: n = 21404
    year = 2013: n = 0
    year = 2014: n = 0
    year = 2015: n = 0
    year = 2016: n = 0
    year = 2017: n = 0
ID Val data...
    year = 2002: n = 221
    year = 2003: n = 294
    year = 2004: n = 210
    year = 2005: n = 305
    year = 2006: n = 390
    year = 2007: n = 159
    year = 2008: n = 286
    year = 2009: n = 985
    year = 2010: n = 2459
    year = 2011: n = 2874
    year = 2012: n = 3300
    year = 2013: n = 0
    year = 2014: n = 0
    year = 2015: n = 0
    year = 2016: n = 0
    year = 2017: n = 0
ID Test data...
    year = 2002: n = 227
    year = 2003: n = 276
    year = 2004: n = 240
    year = 2005: n = 324
    year = 2006: n = 406
    year = 2007: n = 190
    year = 2008: n = 298
    year = 2009: n = 935
    year = 2010: n = 2456
    year = 2011: n = 2837
    year = 2012: n = 3138
    year = 2013: n = 0
    year = 2014: n = 0
    year = 2015: n = 0
    year = 2016: n = 0
    year = 2017: n = 0
OOD Val data...
    year = 2002: n = 0
    year = 2003: n = 0
    year = 2004: n = 0
    year = 2005: n = 0
    year = 2006: n = 0
    year = 2007: n = 0
    year = 2008: n = 0
    year = 2009: n = 0
    year = 2010: n = 0
    year = 2011: n = 0
    year = 2012: n = 0
    year = 2013: n = 3850
    year = 2014: n = 6192
    year = 2015: n = 9873
    year = 2016: n = 0
    year = 2017: n = 0
OOD Test data...
    year = 2002: n = 0
    year = 2003: n = 0
    year = 2004: n = 0
    year = 2005: n = 0
    year = 2006: n = 0
    year = 2007: n = 0
    year = 2008: n = 0
    year = 2009: n = 0
    year = 2010: n = 0
    year = 2011: n = 0
    year = 2012: n = 0
    year = 2013: n = 0
    year = 2014: n = 0
    year = 2015: n = 0
    year = 2016: n = 15959
    year = 2017: n = 6149

Epoch [0]:

Train:
